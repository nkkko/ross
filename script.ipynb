{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis Results:\n",
      "Rank | Repo                                   | Stars at start | Stars at end | Reached 1k stars | End date    | Growth\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "1    | zed-industries_zed_stargazers          | 1000           | 31667        | 24 Jan 2024      | 23 Apr 2024 | 31.7  \n",
      "2    | opendevin_opendevin_stargazers         | 1000           | 27046        | 15 Mar 2024      | 13 Jun 2024 | 27.0  \n",
      "3    | maybe-finance_maybe_stargazers         | 1000           | 25898        | 13 Jan 2024      | 12 Apr 2024 | 25.9  \n",
      "4    | heyputer_puter_stargazers              | 1000           | 19002        | 05 Mar 2024      | 03 Jun 2024 | 19.0  \n",
      "5    | subquery_subql_stargazers              | 1000           | 18542        | 10 Jan 2024      | 09 Apr 2024 | 18.5  \n",
      "6    | stitionai_devika_stargazers            | 1000           | 17633        | 22 Mar 2024      | 20 Jun 2024 | 17.6  \n",
      "7    | hpcaitech_open-sora_stargazers         | 1000           | 17191        | 07 Mar 2024      | 05 Jun 2024 | 17.2  \n",
      "8    | myshell-ai_openvoice_stargazers        | 1000           | 16269        | 02 Jan 2024      | 01 Apr 2024 | 16.3  \n",
      "9    | janhq_jan_stargazers                   | 1000           | 14299        | 02 Jan 2024      | 01 Apr 2024 | 14.3  \n",
      "10   | astral-sh_uv_stargazers                | 1000           | 11723        | 16 Feb 2024      | 16 May 2024 | 11.7  \n",
      "11   | joaomdmoura_crewai_stargazers          | 1000           | 10702        | 01 Jan 2024      | 31 Mar 2024 | 10.7  \n",
      "12   | gitbutlerapp_gitbutler_stargazers      | 1000           | 10457        | 13 Feb 2024      | 13 May 2024 | 10.5  \n",
      "13   | kroma-network_tachyon_stargazers       | 1000           | 7690         | 07 Jan 2024      | 06 Apr 2024 | 7.7   \n",
      "14   | teableio_teable_stargazers             | 1000           | 7407         | 12 Mar 2024      | 10 Jun 2024 | 7.4   \n",
      "15   | conductor-oss_conductor_stargazers     | 1000           | 7371         | 04 Jan 2024      | 03 Apr 2024 | 7.4   \n",
      "16   | leptonai_search_with_lepton_stargazers | 1000           | 6884         | 28 Jan 2024      | 27 Apr 2024 | 6.9   \n",
      "17   | vanna-ai_vanna_stargazers              | 1000           | 6214         | 15 Jan 2024      | 14 Apr 2024 | 6.2   \n",
      "18   | phidatahq_phidata_stargazers           | 1000           | 5635         | 11 Feb 2024      | 11 May 2024 | 5.6   \n",
      "19   | daytonaio_daytona_stargazers           | 1000           | 5584         | 07 Mar 2024      | 05 Jun 2024 | 5.6   \n",
      "20   | vikparuchuri_surya_stargazers          | 1000           | 5444         | 14 Jan 2024      | 13 Apr 2024 | 5.4   \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "def load_data(data_dir):\n",
    "    all_files = glob.glob(os.path.join(data_dir, \"*.pkl\"))\n",
    "    df_list = []\n",
    "    for filename in all_files:\n",
    "        with open(filename, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        df = pd.DataFrame(data)\n",
    "        df['repo'] = os.path.basename(filename).split('.')[0]  # Add repo name\n",
    "        df_list.append(df)\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "def calculate_cumulative_stars(df):\n",
    "    df['starred_at'] = pd.to_datetime(df['starred_at'], utc=True)\n",
    "    df = df.sort_values('starred_at')\n",
    "    df['cumulative_stars'] = df.groupby('repo').cumcount() + 1\n",
    "    return df\n",
    "\n",
    "def find_milestone_date(df, milestone=1000):\n",
    "    return df[df['cumulative_stars'] >= milestone].groupby('repo')['starred_at'].first()\n",
    "\n",
    "def calculate_growth_rate(df, milestone_date, end_date):\n",
    "    start_stars = df[df['starred_at'] <= milestone_date]['cumulative_stars'].max()\n",
    "    end_stars = df[df['starred_at'] <= end_date]['cumulative_stars'].max()\n",
    "    growth_rate = end_stars / start_stars if start_stars > 0 else 0\n",
    "    return {\n",
    "        'start_stars': start_stars,\n",
    "        'end_stars': end_stars,\n",
    "        'growth_rate': growth_rate\n",
    "    }\n",
    "\n",
    "def get_quarter_dates(quarter, year):\n",
    "    quarters = {\n",
    "        '1': (f\"{year}-01-01\", f\"{year}-03-31\"),\n",
    "        '2': (f\"{year}-04-01\", f\"{year}-06-30\"),\n",
    "        '3': (f\"{year}-07-01\", f\"{year}-09-30\"),\n",
    "        '4': (f\"{year}-10-01\", f\"{year}-12-31\")\n",
    "    }\n",
    "    start, end = quarters[quarter.lower()]\n",
    "    return (pd.to_datetime(start).replace(tzinfo=timezone.utc),\n",
    "            pd.to_datetime(end).replace(tzinfo=timezone.utc))\n",
    "\n",
    "def analyze_quarter(df, quarter, year):\n",
    "    quarter_start, quarter_end = get_quarter_dates(quarter, year)\n",
    "\n",
    "    milestone_dates = find_milestone_date(df)\n",
    "    eligible_repos = milestone_dates[milestone_dates <= quarter_end]\n",
    "\n",
    "    results = []\n",
    "    for repo, milestone_date in eligible_repos.items():\n",
    "        end_date = min(milestone_date + timedelta(days=90), quarter_end)\n",
    "\n",
    "        repo_df = df[df['repo'] == repo]\n",
    "        growth_data = calculate_growth_rate(repo_df, milestone_date, end_date)\n",
    "\n",
    "        results.append({\n",
    "            'repo': repo,\n",
    "            'milestone_date': milestone_date.tz_convert(timezone.utc),\n",
    "            'start_date': milestone_date.tz_convert(timezone.utc),\n",
    "            'end_date': end_date.tz_convert(timezone.utc),\n",
    "            'start_stars': growth_data['start_stars'],\n",
    "            'end_stars': growth_data['end_stars'],\n",
    "            'growth_rate': growth_data['growth_rate']\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def print_results_table(results):\n",
    "    # Sort the results by growth_rate in descending order\n",
    "    results = results.sort_values('growth_rate', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Define column headers and corresponding DataFrame column names\n",
    "    columns = [\n",
    "        (\"Rank\", \"rank\"),\n",
    "        (\"Repo\", \"repo\"),\n",
    "        (\"Stars at start\", \"start_stars\"),\n",
    "        (\"Stars at end\", \"end_stars\"),\n",
    "        (\"Reached 1k stars\", \"milestone_date\"),\n",
    "        (\"End date\", \"end_date\"),\n",
    "        (\"Growth\", \"growth_rate\")\n",
    "    ]\n",
    "\n",
    "    # Add rank column\n",
    "    results['rank'] = range(1, len(results) + 1)\n",
    "\n",
    "    # Filter columns that exist in the DataFrame\n",
    "    existing_columns = [(header, col) for header, col in columns if col in results.columns]\n",
    "\n",
    "    # Format date columns\n",
    "    for date_col in ['milestone_date', 'end_date']:\n",
    "        if date_col in results.columns:\n",
    "            results[date_col] = results[date_col].dt.strftime('%d %b %Y')\n",
    "\n",
    "    # Calculate column widths\n",
    "    col_widths = [max(len(str(header)), results[col].astype(str).map(len).max())\n",
    "                  for header, col in existing_columns]\n",
    "\n",
    "    # Print table header\n",
    "    header_row = \" | \".join(f\"{header:<{width}}\" for (header, _), width in zip(existing_columns, col_widths))\n",
    "    print(header_row)\n",
    "    print(\"-\" * len(header_row))\n",
    "\n",
    "    # Print table rows\n",
    "    for _, row in results.iterrows():\n",
    "        row_data = []\n",
    "        for (_, col), width in zip(existing_columns, col_widths):\n",
    "            value = row[col]\n",
    "            if col == 'growth_rate':\n",
    "                value = f\"{value:.1f}\"  # Round to one decimal place\n",
    "            elif isinstance(value, float):\n",
    "                value = f\"{value:.2f}\"\n",
    "            elif isinstance(value, int):\n",
    "                value = f\"{value}\"\n",
    "            else:\n",
    "                value = str(value)\n",
    "            row_data.append(f\"{value:<{width}}\")\n",
    "        print(\" | \".join(row_data))\n",
    "\n",
    "def main():\n",
    "    data_dir = 'data'  # Adjust this to your data directory path\n",
    "    df = load_data(data_dir)\n",
    "    df = calculate_cumulative_stars(df)\n",
    "\n",
    "    quarter = input(\"Enter the quarter (1, 2, 3, 4): \")\n",
    "    year = int(input(\"Enter the year: \"))\n",
    "\n",
    "    results = analyze_quarter(df, quarter, year)\n",
    "\n",
    "    print(\"\\nAnalysis Results:\")\n",
    "    print_results_table(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
